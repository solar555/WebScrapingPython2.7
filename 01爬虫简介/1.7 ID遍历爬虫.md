# 1.7 ID遍历爬虫
　　本节中，我们将利用网站结构的弱点，更轻松地访问所有内容。以下是一些示例国家的URL。
* http://example.webscraping.com/view/Afghanistan-1
* http://example.webscraping.com/view/Australia-2
* http://example.webscraping.com/view/Brazil-3

　　它们的区别在于，结尾格式为“国家 - ID”。在URL中包含页面别名是非常普遍的做法，可以对搜索引擎优化起到帮助作用。Web服务器通常会忽略这个字符串，只是用ID来匹配数据库中的相关记录。我们可以尝试这种方法，看URL是否可用，即将“国家”去掉进行访问（http://example.webscraping.com/view/Afghanistan-1 → http://example.webscraping.com/view/-1）。
　　通过测试可以发现，网页依然可用。现在，我们就只遍历ID来下载所有国家的页面：
```
import itertools
for page in itertools.count(1):
	url = 'http://example.webscraping.com/view/-%d' % page
	html = download(url)
	if html is None:
		break
	else:
		# success - can scrape the result
　　　　pass
```
　　上面的方法存在一种缺陷：当某个页面被删除了，数据库中的ID变为不连续，下载就会失败。下面代码进行了改进，即，在连续多次下载错误后才会退出程序：
```
import itertools

# maximum number of consecutive download errors allowed
max_errors = 5
# current number of consecutive download errors
num_errors = 0

for page in itertools.count(1):
	url = 'http://example.webscraping.com/view/-%d' % page
	html = download(url)
	if html is None:
		# received an error trying to download this webpage
		num_errors += 1
		if num_errors == max_errors:
			# reached maximum number of 
			# consecutive errors so exit
			break
	else:
		# success - can scrape the result
		# ...
		num_errors = 0
```

　　在爬取网站时，遍历ID是一个很便捷的方法，但是和网站地图爬虫一样，它也无法保证始终可用。
　　比如：
　　1. 有些网站会检查页面别名是否满足预期，如果不是，则会返回404 Not Found错误。
　　2. 有些网站会使用<b>非连续大数</b>作为ID
　　3. 有些网站不使用数值作为ID
　　示例：Amazon使用ISBN作为图书ID，这种编码包含至少10位数字，使用ID对Amazon的图书进行遍历需要测试数十亿次，如你想象，效率“高”的让人无法忍受。
　　为此，在下一节将会介绍新的方法。